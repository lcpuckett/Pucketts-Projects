{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "data= pd.read_csv(r\"C:\\Users\\latri\\Desktop\\Latrice tech growth\\Datas\\breastCancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y\n",
    "X = data.drop('diagnosis',axis=1)\n",
    "y = data.diagnosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing and fitting KNN classifier for k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting results using Test data set\n",
    "pred = knn.predict(X_test)\n",
    "accuracy_score(pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FROM A WEBSITE, NOT MY WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What just happened? When we trained the KNN on training data, it took the following steps for each data sample:\n",
    "\n",
    "Calculate the distance between the data sample and every other sample with the help of a method such as Euclidean.\n",
    "Sort these values of distances in ascending order.\n",
    "Choose the top K values from the sorted distances.\n",
    "Assign the class to the sample based on the most frequent class in the above K values.\n",
    "Let’s visualize how KNN drew a decision boundary on the train data set and how the same boundary is then used to classify the test data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the training accuracy of 93% and the test accuracy of 86%, our model might have shown overfitting here. Why so?\n",
    "\n",
    "When the value of K or the number of neighbors is too low, the model picks only the values that are closest to the data sample, thus forming a very complex decision boundary as shown above. Such a model fails to generalize well on the test data set, thereby showing poor results.\n",
    "\n",
    "The problem can be solved by tuning the value of n_neighbors parameter. As we increase the number of neighbors, the model starts to generalize well, but increasing the value too much would again drop the performance.\n",
    "\n",
    "Therefore, it’s important to find an optimal value of K, such that the model is able to classify well on the test data set. Let’s observe the train and test accuracies as we increase the number of neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows an overall upward trend in test accuracy up to a point, after which the accuracy starts declining again. This is the optimal number of nearest neighbors, which in this case is 11, with a test accuracy of 90%.\n",
    "\n",
    "Let’s plot the decision boundary again for k=11, and see how it looks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have improved the results by fine-tuning the number of neighbors. Also, the decision boundary by KNN now is much smoother and is able to generalize well on test data.\n",
    "\n",
    "Let’s now understand how KNN is used for regression.\n",
    "\n",
    "KNN Regressor\n",
    "While the KNN classifier returns the mode of the nearest K neighbors, the KNN regressor returns the mean of the nearest K neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As K increases, the KNN fits a smoother curve to the data. This is because a higher value of K reduces the edginess by taking more data into account, thus reducing the overall complexity and flexibility of the model.\n",
    "\n",
    "As we saw earlier, increasing the value of K improves the score to a certain point, after which it again starts dropping. This can be better understood by the following plot.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see in this figure, the model yields the best results at K=4. I have used R² to evaluate the model, and this was the best we could get. This is because our dataset was too small and scattered.\n",
    "\n",
    "Some other points are important to know about KNN are:\n",
    "\n",
    "KNN classifier does not have any specialized training phase as it uses all the training samples for classification and simply stores the results in memory.\n",
    "KNN is a non-parametric algorithm because it does not assume anything about the training data. This makes it useful for problems having non-linear data.\n",
    "KNN can be computationally expensive both in terms of time and storage, if the data is very large because KNN has to store the training data to work. This is generally not the case with other supervised learning models.\n",
    "KNN can be very sensitive to the scale of data as it relies on computing the distances. For features with a higher scale, the calculated distances can be very high and might produce poor results. It is thus advised to scale the data before running the KNN."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bd13bc16400e16874b7ce28af58a129343287e94248a182c1f06fbb6b76ef8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
